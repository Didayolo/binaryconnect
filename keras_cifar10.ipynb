{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary neural network\n",
    "\n",
    "On veux tester la binarisation des poids du r√©seau neuronal durant l'apprentissage.\n",
    "On le test sur CIFAR-10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use GPU for Theano, comment to use CPU instead of GPU\n",
    "# Tensorflow uses GPU by default\n",
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu,floatX=float32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "% matplotlib inline\n",
    "np.random.seed(2017) \n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To visiualize models\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# If using tensorflow, set image dimensions order\n",
    "from keras import backend as K\n",
    "if K.backend()=='tensorflow':\n",
    "    K.set_image_dim_ordering(\"th\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "# Evolution of learning rate\n",
    "\n",
    "from binary_ops import binary_tanh as binary_tanh_op\n",
    "from binary_layers import BinaryDense, BinaryConv2D, Clip\n",
    "\n",
    "class DropoutNoScale(Dropout):\n",
    "    '''Keras Dropout does scale the input in training phase, which is undesirable here.\n",
    "    '''\n",
    "    def call(self, inputs, training=None):\n",
    "        if 0. < self.rate < 1.:\n",
    "            noise_shape = self._get_noise_shape(inputs)\n",
    "\n",
    "            def dropped_inputs():\n",
    "                return K.dropout(inputs, self.rate, noise_shape,\n",
    "                                 seed=self.seed) * (1 - self.rate)\n",
    "            return K.in_train_phase(dropped_inputs, inputs,\n",
    "                                    training=training)\n",
    "        return inputs\n",
    "\n",
    "def binary_tanh(x):\n",
    "    return binary_tanh_op(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processings : \n",
    "\n",
    "- Global contrast normalization\n",
    "- ZCA whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.misc\n",
    "from PIL import Image\n",
    "from __future__ import division\n",
    "\n",
    "def normalization(X, up):\n",
    "    \"\"\" Normalize X beetween its minimum and up \"\"\"\n",
    "    return (X - np.min(X)) * up / (np.max(X) - np.min(X))\n",
    "\n",
    "def global_contrast_normalization(Y):\n",
    "    \"\"\" Return image after GCN \"\"\"\n",
    "    X = Y.copy()\n",
    "    average = np.mean(X)\n",
    "    dev_stand = np.std(X)\n",
    "    \n",
    "    for i in range(0, len(X)):\n",
    "        av = X[i] - average\n",
    "        dev = av / dev_stand\n",
    "        #X[i] = normalization(dev, 254.0)\n",
    "        X[i] = (dev - np.min(dev)) * 254.0 / (np.max(dev) - np.min(dev))\n",
    "    return X\n",
    "    \n",
    "def zca_whiten(x_train, y_train):\n",
    "    \"\"\"\n",
    "    Function to compute ZCA whitening matrix (aka Mahalanobis whitening).\n",
    "    INPUT:  X_train and y_train\n",
    "    OUTPUT: Whiten X_train\n",
    "    \"\"\"\n",
    "    # Attention, fonction sale\n",
    "    datagen = ImageDataGenerator(zca_whitening=True)\n",
    "\n",
    "    # compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied)\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    flow = datagen.flow(x_train, y_train, batch_size=1, shuffle=False)\n",
    "\n",
    "    whiten_images = []\n",
    "\n",
    "    for _ in range(x_train.shape[0]):\n",
    "        x, y = flow.next()\n",
    "        whiten_images.append(x[0])\n",
    "        \n",
    "    return np.array(whiten_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to load outside CIFAR-10 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#Choisit le test set\n",
    "#Source = blurred, normal, etc..\n",
    "classes = ['airplanes', 'automobiles', 'birds', 'cats', 'deers', 'dogs', 'frogs', 'horses', 'ships', 'trucks']\n",
    "\n",
    "def pick_test_set(source=\"cifar10\"):\n",
    "    # Resized, Rotated, Blurred, ColorsInverted, ContrastDecrease, HighContrast, LowContrast, Noisy, NoisyBlur, NoisyRotated, Others\n",
    "    images = []\n",
    "    labels = []\n",
    "    for dossier, sous_dossiers, fichiers in os.walk(\"Images/\" + source):\n",
    "        split = dossier.split(\"/\")\n",
    "        classe = \"\"\n",
    "        if (len(split) >=3):\n",
    "            classe = split[2]\n",
    "            #print(\"Processing \" + classe + \"...\")\n",
    "        \n",
    "        #Pour l'instant on ne garde que les vraies classes\n",
    "        if (classe != \"birdogs\" and classe != \"birdsdogs\" and classe != \"catsdogs\" and classe != \"others\"):\n",
    "            print(\"Processing \" + classe + \"...\")\n",
    "            \n",
    "            for fichier in fichiers: #Pour chaque image\n",
    "\n",
    "                path = dossier + \"/\"+ fichier\n",
    "                img = cv2.imread(path)\n",
    "                img = img[:,:,::-1] # BGR to RGB\n",
    "                # print(img.shape)\n",
    "                # TODO\n",
    "                image = np.transpose(np.reshape(img,(32,32,3)), (2,0,1)) # To CIFAR format\n",
    "                \n",
    "                labels.append([classes.index(classe)])\n",
    "                images.append(image)\n",
    "                \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CIFAR10 Dataset and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing test data between : cifar10, Resized, Rotated, Blurred, ColorsInverted, ContrastDecrease, \n",
    "#                              HighContrast, LowContrast, Noisy, NoisyBlur, NoisyRotated, Others\n",
    "source = \"cifar10\"\n",
    "##################\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "(train_features, train_labels), (test_features, test_labels) = cifar10.load_data()\n",
    "\n",
    "if source != \"cifar10\":\n",
    "    # USE OUR TEST DATA\n",
    "    test_features, test_labels = pick_test_set(source)\n",
    "\n",
    "num_train, img_channels, img_rows, img_cols =  train_features.shape\n",
    "num_test, _, _, _ =  test_features.shape\n",
    "num_classes = len(np.unique(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save or load pre-processed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def dump_data(data, data_file):\n",
    "    # Save\n",
    "    output = open(data_file, 'wb')\n",
    "    pickle.dump(data, output)\n",
    "    output.close()\n",
    "\n",
    "def load_data(data_file):\n",
    "    # Load\n",
    "    pkl_file = open(data_file, 'rb')\n",
    "    data = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(features, labels):\n",
    "    # Preprocessing on features\n",
    "    \n",
    "    # Global Contrast Normalization\n",
    "    print(\"Global Contrast Normalization...\")\n",
    "    for i in range(len(features)):\n",
    "        features[i] = global_contrast_normalization(features[i])\n",
    "\n",
    "    # Pre-processing\n",
    "    features = features.astype('float32')/255\n",
    "    \n",
    "    # ZCA whitening\n",
    "    print(\"ZCA Whitening...\")\n",
    "    features = zca_whiten(features, labels) \n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "train_features = train_features[:20]\n",
    "test_features = test_features[:20]\n",
    "train_labels = train_labels[:20]\n",
    "test_labels = test_labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train : train.pkl\n",
      "Global Contrast Normalization...\n",
      "ZCA Whitening...\n",
      "Processing test : cifar10.pkl\n",
      "Global Contrast Normalization...\n",
      "ZCA Whitening...\n"
     ]
    }
   ],
   "source": [
    "# Dossier Images/PKL\n",
    "path = \"Images/PKL/\"\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "train_file = \"train.pkl\"\n",
    "test_file = source + \".pkl\"\n",
    "\n",
    "# If train features already preprocessed \n",
    "if os.path.exists(path + train_file): # 50000 CIFAR-10 images\n",
    "    print(\"Loading train : {}\".format(train_file))\n",
    "    train_features = load_data(path + train_file)\n",
    "\n",
    "else:\n",
    "    print(\"Processing train : {}\".format(train_file))\n",
    "    train_features = preprocessing(train_features, train_labels)\n",
    "    dump_data(train_features, path + train_file)\n",
    "\n",
    "# If test features already preprocessed\n",
    "if os.path.exists(path + test_file):\n",
    "    print(\"Loading test : {}\".format(test_file))\n",
    "    test_features = load_data(path + test_file)\n",
    "    \n",
    "else:\n",
    "    print(\"Processing test : {}\".format(test_file))\n",
    "    test_features = preprocessing(test_features, test_labels)\n",
    "    dump_data(test_features, path + test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 3, 32, 32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ni = 21\\n\\nimg = tra[i]\\nimg = normalization(img, 1.0)\\nimg = np.transpose(img, (1, 2, 0))\\nplt.imshow(img)\\nplt.show()\\n#print(img)\\n\\nim = train_features[i]\\nim = np.transpose(im, (1, 2, 0))\\nplt.imshow(im)\\nplt.show()\\n#print(im)\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "i = 21\n",
    "\n",
    "img = tra[i]\n",
    "img = normalization(img, 1.0)\n",
    "img = np.transpose(img, (1, 2, 0))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "#print(img)\n",
    "\n",
    "im = train_features[i]\n",
    "im = np.transpose(im, (1, 2, 0))\n",
    "plt.imshow(im)\n",
    "plt.show()\n",
    "#print(im)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Examples from Each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "low >= high",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1bc394238ad0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mshow_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mshow_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-1bc394238ad0>\u001b[0m in \u001b[0;36mshow_examples\u001b[0;34m(features, labels)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mfeatures_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mimg_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: low >= high"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABaCAYAAADXaio8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAAQZJREFUeJzt3TEKAjEUANF88f5Xjo3lsqLICO57ZUIgTBHS/dl7Lxq3\nX1/gSsQOiR0SOyR2SOzQ/WxzZvwLP7D3nqP109jPg9+/zR+bOey81vKMpMQOiR0SOyR2SOyQ2CGx\nQ2KHxA6JHRI7JHZI7JDYIbFDYofEDokdEjskdkjskNghsUNih8QOiR0SOyR2SOyQ2CGxQ2KHxA6J\nHRI7JHZI7JDYIbFDYofEDokdEjskdkjskNghsUNih8QOiR0SOyR2SOyQ2CGxQ2KHxA6JHRI7JHZI\n7JDYIbFDYofEDokdEjskdkjskNghsUNih8QOvRx3dTa+ifeM2WEdz0hI7JDYIbFDYocecasNtl+J\nxB4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f671a4bc210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# y'a un truc qui deconne, soit ici, soit dans la GCN...\n",
    "\n",
    "def show_examples(features, labels):\n",
    "\n",
    "    class_names = ['airplane','automobile','bird','cat','deer',\n",
    "                   'dog','frog','horse','ship','truck']\n",
    "    fig = plt.figure(figsize=(8,3))\n",
    "    for i in range(num_classes):\n",
    "        ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
    "        idx = np.where(labels[:]==i)[0]\n",
    "        features_idx = features[idx,::]\n",
    "        img_num = np.random.randint(features_idx.shape[0])\n",
    "        im = np.transpose(features_idx[img_num,::], (1, 2, 0))\n",
    "        ax.set_title(class_names[i])\n",
    "        plt.imshow(im)\n",
    "    plt.show()\n",
    "    \n",
    "show_examples(train_features, train_labels)\n",
    "show_examples(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##¬†Convert class labels to binary class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = np_utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = np_utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to plot model accuracy and loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_model_history(model_history):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funtion to compute test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(test_x, test_y, model):\n",
    "    result = model.predict(test_x)\n",
    "    predicted_class = np.argmax(result, axis=1)\n",
    "    true_class = np.argmax(test_y, axis=1)\n",
    "    num_correct = np.sum(predicted_class == true_class) \n",
    "    accuracy = float(num_correct)/result.shape[0]\n",
    "    return (accuracy * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef train_processing(model, callbacks=None, nb_epoch=10, batch_size=128, verbose=1, lr_start=1e-3, lr_end=1e-4, zca_whitening=True, save=False, h5_file=\"model.h5\"):\\n    # Train the model\\n    \\n    lr_decay = (lr_end / lr_start)**(1. / nb_epoch)\\n    \\n    if callbacks==None:\\n        lr_scheduler = LearningRateScheduler(lambda e: lr_start * lr_decay ** e)\\n        callbacks = [lr_scheduler]\\n    \\n    print(\"Pre-processing data...\")\\n    datagen = ImageDataGenerator(zca_whitening=zca_whitening)\\n    # compute quantities required for featurewise normalization\\n    # (std, mean, and principal components if ZCA whitening is applied)\\n    datagen.fit(train_features)\\n    \\n    start = time.time()\\n    if save: # Boolean save means we save the model at each epoch\\n        for _ in range(nb_epoch):\\n            # fits the model on batches with real-time data augmentation:\\n            model_info = model.fit_generator(datagen.flow(train_features, train_labels, batch_size=batch_size),\\n                                steps_per_epoch=len(train_features) / nb_epoch, epochs=1,\\n                                verbose=verbose, callbacks=callbacks)\\n            save_weights(model, h5_file)\\n    else:\\n        # fits the model on batches with real-time data augmentation:\\n        model_info = model.fit_generator(datagen.flow(train_features, train_labels, batch_size=batch_size),\\n                            steps_per_epoch=len(train_features) / nb_epoch, epochs=nb_epoch,\\n                            verbose=verbose, callbacks=callbacks)\\n    end = time.time()\\n    # plot model history\\n    plot_model_history(model_info)\\n    print \"Model took %0.2f seconds to train\"%(end - start)\\n    # compute test accuracy\\n    print \"Accuracy on test data is: %0.2f\"%accuracy(test_features, test_labels, model)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(model, callbacks=None, nb_epoch=10, batch_size=128, verbose=1, lr_start=1e-3, lr_end=1e-4, save=False, h5_file=\"model.h5\"):\n",
    "    # Train the model\n",
    "    \n",
    "    lr_decay = (lr_end / lr_start)**(1. / nb_epoch)\n",
    "    \n",
    "    if callbacks==None:\n",
    "        lr_scheduler = LearningRateScheduler(lambda e: lr_start * lr_decay ** e)\n",
    "        callbacks = [lr_scheduler]\n",
    "    \n",
    "    start = time.time()\n",
    "    if save: # Boolean save means we save the model at each epoch\n",
    "        for _ in range(nb_epoch):\n",
    "            model_info = model.fit(train_features, train_labels, \n",
    "                               batch_size=batch_size, nb_epoch=1, \n",
    "                               validation_data = (test_features, test_labels), \n",
    "                               verbose=verbose, callbacks=callbacks)\n",
    "            save_weights(model, h5_file)\n",
    "        \n",
    "    else:\n",
    "        model_info = model.fit(train_features, train_labels, \n",
    "                               batch_size=batch_size, nb_epoch=nb_epoch, \n",
    "                               validation_data = (test_features, test_labels), \n",
    "                               verbose=verbose, callbacks=callbacks)\n",
    "    end = time.time()\n",
    "    # plot model history\n",
    "    plot_model_history(model_info)\n",
    "    print(type(model_info))\n",
    "    print \"Model took %0.2f seconds to train\"%(end - start)\n",
    "    # compute test accuracy\n",
    "    print \"Accuracy on test data is: %0.2f\"%accuracy(test_features, test_labels, model)\n",
    "    \n",
    "\"\"\"\n",
    "def train_processing(model, callbacks=None, nb_epoch=10, batch_size=128, verbose=1, lr_start=1e-3, lr_end=1e-4, zca_whitening=True, save=False, h5_file=\"model.h5\"):\n",
    "    # Train the model\n",
    "    \n",
    "    lr_decay = (lr_end / lr_start)**(1. / nb_epoch)\n",
    "    \n",
    "    if callbacks==None:\n",
    "        lr_scheduler = LearningRateScheduler(lambda e: lr_start * lr_decay ** e)\n",
    "        callbacks = [lr_scheduler]\n",
    "    \n",
    "    print(\"Pre-processing data...\")\n",
    "    datagen = ImageDataGenerator(zca_whitening=zca_whitening)\n",
    "    # compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied)\n",
    "    datagen.fit(train_features)\n",
    "    \n",
    "    start = time.time()\n",
    "    if save: # Boolean save means we save the model at each epoch\n",
    "        for _ in range(nb_epoch):\n",
    "            # fits the model on batches with real-time data augmentation:\n",
    "            model_info = model.fit_generator(datagen.flow(train_features, train_labels, batch_size=batch_size),\n",
    "                                steps_per_epoch=len(train_features) / nb_epoch, epochs=1,\n",
    "                                verbose=verbose, callbacks=callbacks)\n",
    "            save_weights(model, h5_file)\n",
    "    else:\n",
    "        # fits the model on batches with real-time data augmentation:\n",
    "        model_info = model.fit_generator(datagen.flow(train_features, train_labels, batch_size=batch_size),\n",
    "                            steps_per_epoch=len(train_features) / nb_epoch, epochs=nb_epoch,\n",
    "                            verbose=verbose, callbacks=callbacks)\n",
    "    end = time.time()\n",
    "    # plot model history\n",
    "    plot_model_history(model_info)\n",
    "    print \"Model took %0.2f seconds to train\"%(end - start)\n",
    "    # compute test accuracy\n",
    "    print \"Accuracy on test data is: %0.2f\"%accuracy(test_features, test_labels, model)\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_weights(model, h5_file):\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(h5_file)\n",
    "    print(\"Saved model to disk\")\n",
    "    \n",
    "def load_weights(model, h5_file):\n",
    "    # load weights into new model\n",
    "    model.load_weights(h5_file)\n",
    "    print(\"Loaded model from disk\")\n",
    "    #return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple network, without binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20 samples, validate on 20 samples\n",
      "Epoch 1/2\n",
      "20/20 [==============================] - 1s 29ms/step - loss: 0.9810 - acc: 0.1000 - val_loss: 0.9813 - val_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "20/20 [==============================] - 0s 642us/step - loss: 0.9387 - acc: 0.6000 - val_loss: 0.9813 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA34AAAFRCAYAAAArTH/eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZIkSVLJWfhJkiRJUslZ+EmSJElSyf0/siFX6p+8wwQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6729963e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.callbacks.History'>\n",
      "Model took 1.69 seconds to train\n",
      "Accuracy on test data is: 0.00\n"
     ]
    }
   ],
   "source": [
    "num_unit = 100\n",
    "num_hidden = 3\n",
    "lr_start = 1e-3\n",
    "\n",
    "# BN\n",
    "epsilon = 1e-6\n",
    "momentum = 0.9\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Simple layer\n",
    "model.add(Flatten(input_shape=(3, 32, 32)))\n",
    "for i in range(num_hidden):\n",
    "    model.add(Dense(num_unit, activation='tanh'))\n",
    "    model.add(BatchNormalization(epsilon=epsilon, momentum=momentum, axis=1, name='bn{}'.format(i)))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(num_classes, activation='softmax')) # 10SVM (L2-SVM) coming soon\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='squared_hinge', optimizer=Adam(lr=lr_start), metrics=['acc'])\n",
    "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "train(model, nb_epoch=2)#, save=True, h5_file=\"simple_model.h5\", nb_epoch=100)\n",
    "\n",
    "#load_weights(model, \"simple_model.h5\")\n",
    "#train(model, nb_epoch=1)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper's architecture, without binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "h5_file = \"paper_nb.h5\"\n",
    "from keras.regularizers import l2\n",
    "\n",
    "# BN\n",
    "epsilon = 1e-6\n",
    "momentum = 0.9\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# (2 * 128C3)\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same', input_shape=(3, 32, 32), activation='relu'))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "model.add(BatchNormalization(epsilon=epsilon, momentum=momentum, axis=1, name='bn1'.format(i)))\n",
    "\n",
    "# MP2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25)) # test\n",
    "\n",
    "# (2 * 256C3)\n",
    "model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "model.add(BatchNormalization(epsilon=epsilon, momentum=momentum, axis=1, name='bn2'.format(i)))\n",
    "\n",
    "# MP2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# (2 * 512C3)\n",
    "model.add(Convolution2D(512, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "model.add(BatchNormalization(epsilon=epsilon, momentum=momentum, axis=1, name='bn3'.format(i)))\n",
    "\n",
    "# MP2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten()) # Flat before FC\n",
    "\n",
    "# (2 * 1024FC)\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization(epsilon=epsilon, momentum=momentum, axis=1, name='bn4'.format(i)))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization(epsilon=epsilon, momentum=momentum, axis=1, name='bn5'.format(i)))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(num_classes, activation='linear', W_regularizer=l2(0.01))) # 10SVM (L2-SVM) coming soon\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "train(model, nb_epoch=10)\n",
    "\n",
    "# Load the model\n",
    "# model = load(model, h5_file)\n",
    "\n",
    "# Save the model\n",
    "save(model, h5_file)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple network, with binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "deterministic = True # deterministic or stochastic binarization\n",
    "\n",
    "H = 'Glorot'\n",
    "\n",
    "# network\n",
    "num_unit = 100\n",
    "num_hidden = 3\n",
    "use_bias = False\n",
    "\n",
    "# BN\n",
    "epsilon = 1e-6\n",
    "momentum = 0.9\n",
    "\n",
    "# dropout\n",
    "drop_in = 0.2\n",
    "drop_hidden = 0.5\n",
    "\n",
    "# lr\n",
    "lr_start = 1e-3\n",
    "\n",
    "model = Sequential()\n",
    "model.add(DropoutNoScale(drop_in, input_shape=(3, 32, 32), name='drop0'))\n",
    "model.add(Flatten())\n",
    "for i in range(num_hidden):\n",
    "    model.add(BinaryDense(num_unit, H=H, use_bias=use_bias, # deterministic=deterministic\n",
    "              name='dense{}'.format(i+1)))\n",
    "    model.add(BatchNormalization(epsilon=epsilon, momentum=momentum, name='bn{}'.format(i+1)))\n",
    "    model.add(Activation(binary_tanh, name='act{}'.format(i+1)))\n",
    "    model.add(DropoutNoScale(drop_hidden, name='drop{}'.format(i+1)))\n",
    "# Output layer\n",
    "model.add(BinaryDense(10, H=H, use_bias=use_bias, # deterministic=deterministic\n",
    "          name='dense'))\n",
    "model.add(BatchNormalization(epsilon=epsilon, momentum=momentum, name='bn'))\n",
    "\n",
    "model.summary()\n",
    " \n",
    "model.compile(loss='squared_hinge', optimizer=Adam(lr=lr_start), metrics=['acc'])\n",
    "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "#train(model, lr_start=lr_start)\n",
    "\n",
    "model = load_weights(model, \"test.h5\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary weights complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "#model = Sequential()\n",
    "\n",
    "\"\"\"\n",
    "model.add(BinaryConv2D(128, deterministic=deterministic, kernel_size=kernel_size, input_shape=(channels, img_rows, img_cols),\n",
    "                       data_format='channels_first',\n",
    "                       H=H, kernel_lr_multiplier=kernel_lr_multiplier, \n",
    "                       padding='same', use_bias=use_bias, name='conv1'))\n",
    "model.add(BatchNormalization(epsilon=epsilon, momentum=momentum, axis=1, name='bn1'))\n",
    "\"\"\"\n",
    "\n",
    "# Load the model\n",
    "# model = load(model, h5_file)\n",
    "\n",
    "# Save the model\n",
    "#save(model, yaml_file, h5_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(zoom_range=0.2, \n",
    "                             horizontal_flip=True)\n",
    "\n",
    "\n",
    "# train the model\n",
    "start = time.time()\n",
    "# Train the model\n",
    "model_info = model.fit_generator(datagen.flow(train_features, train_labels, batch_size = 128),\n",
    "                                 samples_per_epoch = train_features.shape[0], nb_epoch = 200, \n",
    "                                 validation_data = (test_features, test_labels), verbose=0)\n",
    "end = time.time()\n",
    "print \"Model took %0.2f seconds to train\"%(end - start)\n",
    "# plot model history\n",
    "plot_model_history(model_info)\n",
    "# compute test accuracy\n",
    "print \"Accuracy on test data is: %0.2f\"%accuracy(test_features, test_labels, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
